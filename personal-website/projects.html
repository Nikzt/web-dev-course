<!DOCTYPE html>

<html>
<head>
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<meta charset="utf-8">
	<link rel="stylesheet" type="text/css" href="app.css">
	<link href="https://fonts.googleapis.com/css?family=M+PLUS+1p|M+PLUS+Rounded+1c" rel="stylesheet">
  <script src="https://code.jquery.com/jquery-3.3.1.min.js"
  integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
  crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.bundle.min.js" integrity="sha384-pjaaA8dDz/5BgdFUPX6M/9SUZv4d12SUPF0axWc+VRZkx5xU3daN+lYb49+Ax+Tl" crossorigin="anonymous"></script>
	<link rel="stylesheet" type="text/css" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css">
	<title>Bence Linder / Projects</title>
</head>
<body>


<div class="container" id="nameContainer"> 
	<div class="row">
		<div class="col-lg-12">
			<span class="homeTitle">Bence Linder / 
			<span class="dropdown align-baseline">
			  <button class="btn btn-default dropdown-toggle" type="button" id="dropdownMenuButton" data-toggle="dropdown" aria-haspopup="true" aria-expanded="true">
			    Projects
			  </button>
			  <div class="dropdown-menu" id="main-menu" aria-labelledby="dropdownMenuButton">
			    <a class="menu-item dropdown-item" href="games.html">Games</a>
			    <a class="menu-item dropdown-item" href="art.html">Art</a>
			  </div>
			</span></span>
			<hr id="nameLine"></hr>
		</div>
	</div>
</div>

<div class="container" id="post">
	<div class="row">
		<div class="col-lg-12">
		<h1 id="post-title">Genetic Algorithms in Game Testing</h1>
		
		<p id="intro">This was done by myself under the supervision of Steve Engels as my final computer science project at the University of Toronto</p>
		
		<hr id="nameLine"></hr>
		
		<p> One of the reasons that balancing a game is so difficult is that it requires a lot of game testing and user feedback to identify problems, which can be expensive and time consuming. Actually fixing the problems in a game's mechanics requires in depth knowledge of the game, which can be biased as the developer has a different perspective of it than the end user. 
		</p>
		
		<p>What we propose to help deal with these difficulties is fairly simple conceptually; let AI agents play the game, with natural selection determining their behaviour traits. Eventually, local optimum AI parameters will emerge, which is already useful in itself, but going through this process also provides valuable data that can be used to analyze the AI, game mechanics, and levels.</p>
		
		<h2>The Testing Environment</h2>
		
		<p>The ideal canditate for our testing environment would be a simple deathmatch game with AI player implementation, all with accessible source code. Deathmatch works well for a genetic algorithm since the environment is perfectly suited for natural selection, and having access to the source code is required to implement the algorithm as the AI has to be modified. Luckily, we found just what we were looking for in the <a href="https://assetstore.unity.com/packages/templates/systems/deathmatch-ai-kit-45894" target="_blank">Deathmatch AI Kit</a> from the Unity Asset Store.</p>
		
		<img src="ga-project-files/deathmatch-ai-kit.png">
		
		<p>The Deathmatch AI Kit by Opsive features a single map, a behaviour tree visual scripting tool, and a simple implementation of a third-person deathmatch shooter with AI opponents. While not as good as having an established game to work with, it would do for a proof-of-concept.</p>
		
		<img id="deathmatchMap" src="ga-project-files/deathmatch-map.png">
		
		<h2>Setup</h2>
		
		<p>The next step was to implement the genetic algorithm. First, we looked for parameters in the behaviour tree of the AI that could be adjusted, as well as implementing some new parameters:</p>
		
		<ul>
		<li><strong>Cover Probability:</strong> Probability that the agent camps in cover for some amount of time when passing by a cover point</li>
		<li><strong>Flee HP Threshold:</strong> If the agent's health is below this threshold, they will flee from the attacker</li>
		<li><strong>Flee Distance:</strong> If the attacker is beyond this distance threshold, the agent will flee</li>
		<li><strong>Find HP Threshold:</strong> If the agent's health is below this threshold and they are not being attacked, they will search for a health pack</li>
		<li><strong>Attack Range:</strong> The distance the agent will try to keep from its target while attacking</li>
		<li><strong>Patrol Type:</strong> If the agent is not in combat or looking for health, they will use one of these policies to patrol the map
			<ul>
			  <li><strong>Random:</strong> Randomly patrol the map</li>
			  <li><strong>Directional:</strong> Patrol the map in a pre-determined path</li>
			  <li><strong>Long Camp:</strong> Stay on the platforms overlooking the central area of the map</li>
			  <li><strong>Short Camp:</strong> Wait for enemies by the health packs in the outer parts of the map</li>
			</ul>
		</li>
		<li><strong>Weapon:</strong> This determines which weapon the agent will start with. They will only use this weapon.</li>
			<ul>
			  <li><strong>Shotgun</strong></li>
			  <li><strong>SMG</strong></li>
			  <li><strong>Assault Rifle</strong></li>
			  <li><strong>Sniper Rifle</strong></li>
			</ul>
		</ul>
		
		<img src="ga-project-files/SoloTreeExpanded.png">
		
		<p>All of these parameters need to be encoded into "chromosomes", so that when an agent is given this chromosome, their parameters will be set in accordance. Each parameter is represented by a 3-bit number, which is expressed differently depending on the parameter. For example, health threshold values are in the range 0 - 100, and weapons are mapped explicitly to certain bit values.</p>
		
		
		<p>Together, all of the parameters make up a 27-bit chromosome.</p>
		
		<img src="ga-project-files/chromosome-parameters.png">
		
		<p>Once we had chromosomes, it was time to implement selection and crossover to complete the algorithm. More specifically, we used a version of the CHC genetic algorithm which worked better for smaller populations.</p>
		
		<ol>
		<li><strong>Initialize Population:</strong> 32 chromosomes are generated randomly, which serves as the initial population</li>
		<li><strong>Evaluation:</strong> 4 games of deathmatch are played, each with 8 agents receiving a chromosome to determine their parameters. At the end of each game, the agents' scores are linked to their chromosomes.</li>
		<li><strong>Crossover:</strong> Chromosomes are paired randomly to produce 2 offspring for each pair. The new chromosomes are created by exchanging half of the non-matching bits of their parents.</li>
		<li><strong>Evaluation:</strong> The new child population is evaluated.</li>
		<li><strong>Selection:</strong> The child population and the parent population are sorted by score, and the bottom half of chromosomes are eliminated. This becomes the new parent population.</li>
		</ol>
		
		<p>Steps 4 and 5 are then repeated until the population converges (ie. there is little variation in the population), at which point the algorithm restarts with the initial population being generated by flipping 35% of the bits of the highest scoring chromosome.</p>
		
		
		<h2>Implementation Details</h2>
		<div class="container" id="logoGroup">
		<div class="row">
			<div class="col-lg-12">
				<img id="unityLogo" src="ga-project-files/unity-logo.png">
			</div>
		</div>
		<div class="row">
			<div class="col-lg-6 col-md-6 col-sm-6 col-xs-6">
				<img id="csharpLogo" src="ga-project-files/c-sharp-logo.png">
			</div>
			<div class="col-lg-6 col-md-6 col-sm-6 col-xs-6">
				<img id="bashLogo" src="ga-project-files/bash-logo.png">
			</div>
		</div>
		</div>

		<p>All of the data structures and logic behind the genetic algorithm was implemented in the Unity game engine using C# as the scripting language, except for getting multiple instances of the game to communicate with each other. The reason for having multiple games running at once was to increase the population, as fitting more agents into a single game would make the small map too crowded, influencing the results.</p>
		
		<p>To do this, we had each game log information into text files. At each iteration, 4 games would start, and they pull from the pool of unevaluated chromosomes to populate the map. The shell script responsible for running the games would not start the next batch of games until all of the games in the current batch had finished running.</p>

		
		<h2>Running the Tests</h2>
		
		<p>The algorithm would run games until we decided to stop it. Since it took anywhere from 3 to 5 hours for some sort of convergence to happen, we would typically just let it run overnight. This was eventually sped up by running it in a no-graphics mode, and accelerating the game time. Usually we would get through 100 - 200 generations before we stopped running a test.</p>
		
		<p>The results were collected in the form of a large CSV file which was filled with the current population's parameters and fitness at each iteration. This allowed us to see the entire evolutionary history as the optimal parameter configurations emerged.</p>
		
		<img src="ga-project-files/data-screenshot.png">
		
		<p>In the image above, we have the script that runs the games (top left), the file containing the parameters of each generation's population (right), and the current population's chromosomes and fitness (bottom left)</p>
		
		<h2>Results</h2>
		
		<p>Running the genetic algorithm pointed out a lot of problems in game balance. Most of this had to do with the weapons, which we added ourselves. The reason for adding new weapons was that the weapons already in the Deathmatch AI Kit were not conducive to the agents expressing different play styles, since there was only an assault rifle and a rocket launcher pick-up on the map. We added the SMG, shotgun, and sniper rifle in the hopes that different parameter configurations would emerge for different weapons. Unfortunately, our manually balanced weapon damage values tended to make one or two weapons much better than the rest, causing the algorithm to converge on these weapon choices too quickly.</p>
		
		<img src="ga-project-files/weapon-usage-unbalanced.png">
		
		<p>In the case of a multiplayer shooter, we wouldn't want picking the best weapon to be such an easy choice. If the weapons were balanced, the algorithm should converge on a weapon choice at a much slower rate, or not at all.</p>
		
		<p>To remedy this, we implemented an automated weapon balancing system that would adjust the weapon damage values if one weapon choice made up a significant portion of the population. This succeeded in enforcing a diversity of weapon choices, making for a more balanced game.</p>
		
		<img src="ga-project-files/weapon-usage-balanced.png">
		
		<p>Another insight into the game due to the genetic algorithm was that the agents' use of cover was highly flawed. This was discovered when we noticed that in every test we had run, the cover probability paramter quickly converged toward 0, even when we modified the fitness function to heavily incentivize staying alive.</p>
		
		<img src="ga-project-files/cover-probability.png">
		
		<p>As it turned out, the cover action that was implemented by Opsive (the creators of the Deathmatch AI Kit), was so slow that it was detrimental to ever take cover at all. In addition, none of the cover points on the map actually hid the whole body of a player. This would have been very difficult to notice by just observing gameplay without knowing what to look for, so the utility of running the genetic algorithm to diagnose these problems is clear.</p>
		
		<p>The last important result is from something that was not discovering game balance issues, but rather a bit of validation that the genetic algorithm would find different gameplay strategies for the agents based on changes to the game's rules. We ran two tests, each with different fitness functions, hoping to incentivize an aggressive play style in one and a defensive play style in the other.</p>
		
		<img src="ga-project-files/optimal-death-penalty.png">
		<img src="ga-project-files/optimal-kill-reward.png">
		
		<p>The results are as expected, which shows that this method of tuning AI agents can serve as a simulated player population that responds to changes in game mechanics, providing useful data to be considered in the game testing process.</p>
		

		</div>
	</div>
</div>

</body>
</html>
